{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Previous experiments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from transformers import BertGenerationEncoder, BertGenerationDecoder, EncoderDecoderModel, BertTokenizer, TrainingArguments, Trainer, Seq2SeqTrainer, Seq2SeqTrainingArguments \n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import math \n",
    "\n",
    "from hana_ml import dataframe\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from rouge import Rouge\n",
    "rouge = Rouge()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MEANSUM model for cluster summary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "source": [
    "load_dotenv()\n",
    "conn = dataframe.ConnectionContext(address='localhost', port=30015, user=os.getenv('hana_user'), password=os.getenv('hana_password'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "source": [
    "clusters = conn.table('SAP_NEWS_CENTER_TOPICCLUSTERS', schema=os.getenv('hana_nc_schema'))\n",
    "df_108 = clusters.filter(\"CLUSTER_LABEL = 108\").select(\"START_DATE\", \"ARTICLE_ID\").collect()\n",
    "\n",
    "ids = ','.join([\"'\"+id+\"'\" for id in df_108['ARTICLE_ID'].tolist()])\n",
    "df_108_articles = conn.table('SAP_NEWS_CENTER_ARTICLES', schema=os.getenv('hana_nc_schema')).filter(f\"ID in ({ids})\").collect()\n",
    "\n",
    "cluster_content = df_108_articles.iloc[[1,2,3,4,5,8,12,13]]['CONTENT'].tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "autoencoder = EncoderDecoderModel.from_pretrained('../saved-models/bert2bert/content-reconstruction/v3')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "\n",
    "encoder = autoencoder.get_encoder()\n",
    "decoder = autoencoder.get_decoder()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "cont = tokenizer(['Mein Name ist Marco und ich spiele gerne Fussball'], return_tensors=\"pt\")\n",
    "gen = autoencoder.generate(cont.input_ids)\n",
    "tokenizer.decode(gen[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[CLS] Mein Name ist Marco und ich spiele gerne Fussballballball [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] mein Name ist Marco und ich spiele gerne Fussball ist Marco und ich spiele gerne Fussballball [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] mein Name ist [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] mein Name ist Marco und ich spiele gerne spiele gerne Fussballe gerne Fussballball [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] Mein Name ist Marco und ich ich spiele gerne spiele gerne Fussballballballball [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] Mein und ich ich spiele gerne Fuss [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] Mein Name ist Marco und ich spiel Fussball [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] Mein Name [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] Mein und [SEP] [SEP] [SEP] Meine gerne Fussballballball [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] Mein und [SEP] [SEP] [SEP] [SEP] [SEP] Mein Name [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] Mein und ich ich spiele gerne spiele gerne Fussballballballballballball [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] Mein Name ist Marco und Mein und Mein Name ist Marco und ich spiel Fussball [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "source": [
    "tokenized_content = tokenizer(cluster_content, padding=\"max_length\", truncation=True, max_length=512, add_special_tokens=True, return_tensors=\"pt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "source": [
    "encoded_vectors = encoder(tokenized_content.input_ids, attention_mask=tokenized_content.attention_mask).last_hidden_state\n",
    "mean = torch.mean(encoded_vectors, dim=0, keepdim=True)\n",
    "\n",
    "decoder_input_ids = torch.tensor([[autoencoder.config.encoder.bos_token_id]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "source": [
    "i = 0\n",
    "max_i = 512\n",
    "\n",
    "while i < max_i:\n",
    "    i = i+1\n",
    "    outputs = decoder(decoder_input_ids, encoder_hidden_states=mean)\n",
    "    next_decoder_input_ids = torch.argmax(outputs.logits[:, -1:], axis=-1)\n",
    "    decoder_input_ids = torch.cat([decoder_input_ids, next_decoder_input_ids], axis=-1)\n",
    "    if next_decoder_input_ids[0][0] == decoder.config.pad_token_id:\n",
    "        print(\"End of Summary!\")\n",
    "        break\n",
    "    \n",
    "summary = tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True)\n",
    "summary"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Der Vorsitzende der Ständigen Impfkommission in dere, der der, der der Ständigen Der Chef der Vorsitzende der Vorsitzende, der der Ständigen, der für die die Der der Vorsitzende der Vorsitzende dere der der und der von Der bei der Vorsitzende der die in den auf den Impfstoff für der Empfehlung der Ständigen, und die die die in den den Menschen nach der Ständigen, dass der Impfung von der Impfung für die die in der der und sind, der der Ständige die die und die Empfehlung der Ständigen Impfung in der in der der und die für der Ständigen Impfung, die der die die Impfung von der EU - Stiko -, der der der Ständigen und die in der in der der, die die nach der die nach der Ständigen die nach der und die für die Corona - die die wegen der und die für der, wie die drei Millionen Millionen Menschen als eine von der in der die, wie die'"
      ]
     },
     "metadata": {},
     "execution_count": 328
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adapted MEANSUM Theory for unsupervised single document summary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment 1\n",
    "Try to split the text tokens into target summary size and reconstruct the texts for this size\n",
    "Model is trained for 512 token length, but we will try if it is capable of reconstructing e.g. 128 token length text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "source": [
    "# Take any text for experiment\n",
    "text = cluster_content[3]\n",
    "text"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'STIKO-Mitglied Zepp hält eine begrenzte Empfehlung der Kinder-Impfungen für plausibel.\\n(Foto: picture alliance / dpa)\\nDie Bundesregierung will in der kommenden Woche, auch Kinder ab zwölf Jahre in die Impfkampagne einbeziehen. Die Zulassung eines Vakzins liegt bereits vor, aber noch fehlt die Empfehlung der STIKO. Deren Mitglied Zepp gibt im Interview mit ntv einen Einblick in die Überlegungen der Kommission.\\nntv: Es wird wieder viel über Schüler diskutiert. Viele gehen seit gestern in ganzer Klassenstärke in die Schule. Ist das eine richtige Entscheidung?\\nFred Zepp: Ja. Wir haben nach den Ferien empfohlen, den Schulbetrieb wieder zunehmen. Angesichts der deutlich rückläufigen Infektionslage plus der Rahmenbedingungen plus der Erfahrungen, die wir gemacht haben, dass es in Schulen besonders gut funktioniert mit den Hygiene-Regeln, ist es aus unserer Sicht zulässig. Vor allen Dingen ist es wichtig für Kinder und Jugendliche, endlich wieder in einen normalen Schulbetrieb zurückgeführt zu werden.\\nSeit gestern gibt es auch endgültig grünes Licht für den Biontech-Impfstoff für Kinder ab zwölf. Ist das auch wichtig für Kinder und Jugendliche?\\nDas ist grundsätzlich was Wichtiges. Allerdings ist es tatsächlich nicht besonders wichtig für die Wiedereröffnung der Schulen oder für die Wiederaufnahme des Präsenzunterrichts.\\nWofür ist es denn dann wichtig, dass man einen Impfstoff hat, der für Kinder zugelassen ist?\\nOhne große Krankheitslast brauchen Kinder und Jugendlichen eigentlich keine Impfung, um sich vor Krankheiten zu schützen. Es gibt aber eine Untergruppe von Kindern, die zum Beispiel chronische Lungenerkrankungen haben wie Mukoviszidose oder Kinder mit schwerwiegendem Herzfehler, Stoffwechselerkrankungen oder Trisomie21, von der wir wissen, dass sie ein höheres Risiko für einen schwerwiegenden Krankheitsverlauf haben. Das sind die, die wir zunächst im Auge haben und prüfen müssen, ob wir sie zuverlässig durch eine Impfung schützen können.\\n Ist es richtig, dass etwa Schülervertreter sagen, genau für diese Gruppe sollte der Impfstoff dann auch reserviert werden?\\nJa absolut! Wir haben im Augenblick noch begrenzt Mengen verfügbarer Impfstoffe und insofern muss man schauen, wo ist der Impfstoff am sinnvollsten eingesetzt. Wenn wir jetzt fünf oder drei Millionen Jugendliche impfen würden, dann würden wir den besonders gefährdeten Menschen eigentlich diesen Impfstoff wegnehmen. Noch immer sind 30 Prozent der hochpriorisierten, risikobelasteten Menschen nicht geimpft, während Kinder im Prinzip nicht erkranken. Und wir wissen auch: Kinder geben den Infektionserreger nicht so intensiv weiter.\\nVerstehe ich Sie dann richtig, dass Sie die angekündigte Aufhebung der Priorisierung nicht so gut finden?\\nWenn man mich gefragt hätte, hätte ich empfohlen, noch ein bisschen zu warten, bis dass wir die Risikogruppen in unserer Gesellschaft wirklich geschützt haben. Dass das gut funktioniert, sehen wir daran, dass wir jetzt sehr sehr viel weniger ältere Menschen mit schweren Verläufe haben, die auf Intensivstation liegen. Das Konzept, die am höchsten gefährdeten zunächst zu impfen, funktioniert. Wir hätten uns noch ein, zwei Wochen Zeit geben sollen, um wirklich erfolgreich diese Risikogruppen zu impfen.\\nLassen Sie uns nochmal über die Zulassung des Impfstoffes für Kinder durch die EMA und jetzt auch das grüne Licht durch die EU sprechen. Eine Impfempfehlung der STIKO gibt es ja nicht. Was ist der Unterschied zwischen einer Zulassung und einer Impfempfehlung?\\nEine Zulassungsbehörde prüft die Unterlagen, die ein Medizinproduktehersteller oder ein Impfstoffhersteller einreicht. Im Augenblick haben wir eine Situation, in der Zulassungsbehörden in Betracht ziehen, höhere Risiken zu akzeptieren, weil die Bedrohung durch die Infektionskrankheit so stark ist. In den USA etwa gibt es dann eine Notfallzulassung. Die signalisiert: nicht komplett geprüft! In Europa sind wir etwas sorgfältiger. Wir haben eine bedingte Zulassung. Dabei vermittelt die Behörde, dass die Daten nicht in dem Umfang vorliegen, wie sie es normalerweise erwarten würden. Trotzdem gibt es seit 1972 in Deutschland die Ständige Impfkommission. Die STIKO hat nur den Auftrag, aus der Menge der verfügbaren Impfstoffe die zu empfehlen, die hierzulande am besten Krankheiten oder Seuchen verhindern. Gleichzeitig aber muss sie auch betrachten: Ist das sicher? Würden wir die Zulassungsrahmenbedingungen 1:1 übernehmen, bräuchten wir keine STIKO. Sie trifft eine Empfehlung im Rahmen der Zulassung und kann nicht über die Zulassung hinausgehen. Aber sie kann sie einschränken.\\nÄrgert Sie es, wenn Bundesgesundheitsminister Jens Spahn sagt, ich will in den Sommerferien alle Kinder ab zwölf impfen? Fühlen sie sich dann übergangen oder nicht ernstgenommen?\\nIch finde es ein bisschen schade. Ich glaube, das ist auch die Wahrnehmung vieler meiner Kolleginnen und Kollegen in diesem Gremium. Wir haben vor 50 Jahren vorausschauend ein solches Expertengremium ins Leben gerufen mit dem Ziel, Politik zu beraten. Tatsächlich entwickeln wir nur Empfehlungen. Doch dahinter steckt eine ausführliche, wissenschaftlich belegte Begründung. Und jetzt muss man mal sagen, Impfempfehlungen sind ja nicht \"Wünsch dir was\", sondern es geht darum, Gesundheit zu erhalten, Infektionen zu verhindern und den Menschen ein sicheres Konzept an die Hand zu geben. Ich kann aber wiederum nachvollziehen, dass Politiker es gerne mal anders hätten, weil sie ein bestimmtes politisches Ziel als opportun ansehen und erreichen wollen. Aber das darf nicht dazu führen, dass wir Sicherheitskonzepte, Entscheidungsprinzipien einfach achtlos über Haufen werfen.\\nWann kommt denn nun die STIKO-Empfehlung zu den Impfungen für Kinder und Jugendliche?\\nDie Empfehlungen wird voraussichtlich nächste Woche kommen. Viel schneller geht es nicht, weil Kommunikationsschritte zwischen den Bundesländern dem Robert-Koch-Institut und der STIKO organisatorisch vorgegeben sind.\\nMan muss kein Prophet sein, um zu erwarten, dass das dann eine Empfehlung für vorerkrankte Kinder sein wird, richtig?\\nEs ist eine ziemlich plausible Überlegung.\\nMit Fred Zepp sprach Doro Steitz\\nQuelle: ntv.de'"
      ]
     },
     "metadata": {},
     "execution_count": 336
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "source": [
    "tokenized_content = tokenizer(text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "tokenized_content.input_ids.size()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1234])"
      ]
     },
     "metadata": {},
     "execution_count": 337
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "source": [
    "split_size = int(math.ceil(1234/9))\n",
    "splitted_input_ids = torch.split(tokenized_content.input_ids, split_size, 1)\n",
    "splitted_attention_mask = torch.split(tokenized_content.attention_mask, split_size, 1)\n",
    "\n",
    "input_data = []\n",
    "\n",
    "splitted_input_ids = [torch.cat([torch.tensor([[autoencoder.config.encoder.bos_token_id]]), t], dim=1) for t in splitted_input_ids]\n",
    "splitted_attention_mask = [torch.cat([torch.tensor([[1]]), t], dim=1) for t in splitted_attention_mask]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "source": [
    "input_ids = torch.stack(list(splitted_input_ids[:8]), 1).squeeze()\n",
    "attention_mask = torch.stack(list(splitted_attention_mask[:8]), 1).squeeze()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "source": [
    "generated = autoencoder.generate(input_ids, attention_mask=attention_mask, max_length=split_size, decoder_start_token_id=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "source": [
    "reconstructed_text = ' '.join(tokenizer.batch_decode(generated, skip_special_tokens=True))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "source": [
    "reconstructed_text"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'STIKO - Mitglied Zepp hält eine begrenzte Empfehlung der Kinder - Impfungen für plausibel. ( Foto : picture alliance / dpa ) Die Bundesregierung will in der kommenden Woche, auch Kinder ab zwölf Jahre in die Impfkampagne einbeziehen. Die Zulassung eines Vakzins liegt bereits vor, aber noch fehlt die Empfehlung der STIKO. Deren Mitglied Zepp gibt im Interview mit ntv einen Einblick in die Überlegungen der Kommission. ntv : Es wird wieder viel über Schüler diskutiert. Viele gehen seit gestern in ganzer Klassenstärke in die Schule. Ist das eine richtige Entscheidung? Fred Zepp : Ja. Wir haben nach den Ferien empfohlen den Schulbetrieb wieder zunehmen. Angesichts der deutlich rückläufigen Infektionslage plus der Rahmenbedingungen plus der Erfahrungen, die wir gemacht haben, dass es in Schulen besonders gut funktioniert mit den Hygiene - Regeln, ist es aus unserer Sicht zulässig. Vor allen Dingen ist es wichtig für Kinder und Jugendliche, endlich wieder in einen normalen Schulbetrieb zurückgeführt zu werden. Seit gestern gibt es auch endgültig grünes Licht für den Biontech - Impfstoff für Kinder ab zwölf. Ist das auch wichtig für Kinder und Jugendliche? Das ist grundsätzlich was Wichtiges. Allerdings ist es tatsächlich nicht besonders wichtig für die Wiedereröffnung der Schulen oder für die Wiederaufnahme des Präsenzunterrichts. Wofür ist es denn dann , dass man einen Impfstoff hat, der für Kinder zugelassen ist? Ohne große Krankheitslast brauchen Kinder und Jugendlichen eigentlich keine Impfung, um sich vor Krankheiten zu schützen. Es gibt aber eine Untergruppe von Kindern, die zum Beispiel chronische Lungenerkrankungen haben wie Mukoviszidose oder Kinder mit schwerwiegendem Herzfehler, Stoffwechselerkrankungen oder Trisomie21, von der wir wissen, dass sie ein höheres Risiko für einen schwerwiegenden Krankheitsverlauf haben. Das sind die, die wir zunächst im Auge haben und prüfen müssen, ob wir sie zuverlässig durch eine Impfung schützen können. Ist es richtig, dass etwa Schülervertreter sagen, genau für diese Gruppe sollte der ##stoff dann auch reserviert werden? Ja absolut! Wir haben im Augenblick noch begrenzt Mengen verfügbarer Impfstoffe und insofern muss man schauen, wo ist der Impfstoff am sinnvollsten eingesetzt. Wenn wir jetzt fünf oder drei Millionen Jugendliche impfen würden, dann würden wir den besonders gefährdeten Menschen eigentlich diesen Impfstoff wegnehmen. Noch immer sind 30 Prozent der hochpriorisierten, risikobelasteten Menschen nicht geimpft, während Kinder im Prinzip nicht erkranken. Und wir wissen auch : Kinder geben den Infektionserreger nicht so intensiv weiter. Verstehe ich Sie dann richtig, dass Sie die angekündigte Aufhebung der Priorisierung nicht so gut finden? Wenn man mich gefragt , hätte ich empfohlen, noch ein bisschen zu warten, bis dass wir die Risikogruppen in unserer Gesellschaft wirklich geschützt haben. Dass das gut funktioniert, sehen wir daran, dass wir jetzt sehr sehr viel weniger ältere Menschen mit schweren Verläufe haben, die auf Intensivstation liegen. Das Konzept, die am höchsten gefährdeten zunächst zu impfen, funktioniert. Wir hätten uns noch ein, zwei Wochen Zeit geben sollen, um wirklich erfolgreich diese Risikogruppen zu impfen. Lassen Sie uns nochmal über die Zulassung des Impfstoffes für Kinder durch die EMA und jetzt auch das grüne Licht durch die EU sprechen. Eine Impfempfehlung der STIKO gibt es ja nicht Was ist der Unterschied zwischen einer Zulassung und einer Impfempfehlung? Eine Zulassungsbehörde prüft die Unterlagen, die ein Medizinproduktehersteller oder ein Impfstoffhersteller einreicht. Im Augenblick haben wir eine Situation, in der Zulassungsbehörden in Betracht ziehen, höhere Risiken zu akzeptieren, weil die Bedrohung durch die Infektionskrankheit so stark ist. In den USA etwa gibt es dann eine Notfallzulassung. Die signalisiert : nicht komplett geprüft! In Europa sind wir etwas sorgfältiger. Wir haben eine bedingte Zulassung. Dabei vermittelt die Behörde, dass die Daten nicht in dem Umfang vorliegen, wie sie es normalerweise erwarten würden. Trotzdem gibt es seit 1972 in Deutschland die Ständige Impfkommission. Die S ##IKO hat nur den Auftrag, aus der Menge der verfügbaren Impfstoffe die zu empfehlen, die hierzulande am besten Krankheiten oder Seuchen verhindern. Gleichzeitig aber muss sie auch betrachten : Ist das sicher? Würden wir die Zulassungsrahmenbedingungen 1 : 1 übernehmen, bräuchten wir keine STIKO. Sie trifft eine Empfehlung im Rahmen der Zulassung und kann nicht über die Zulassung hinausgehen. Aber sie kann sie einschränken. Ärgert Sie es, wenn Bundesgesundheitsminister Jens Spahn sagt, ich will in den Sommerferien alle Kinder ab zwölf impfen? Fühlen sie sich dann übergangen oder nicht ernstgenommen? Ich finde es ein bisschen schade. Ich glaube, ist auch die Wahrnehmung vieler meiner Kolleginnen und Kollegen in diesem Gremium. Wir haben vor 50 Jahren vorausschauend ein solches Expertengremium ins Leben gerufen mit dem Ziel, Politik zu beraten. Tatsächlich entwickeln wir nur Empfehlungen. Doch dahinter steckt eine ausführliche, wissenschaftlich belegte Begründung. Und jetzt muss man mal sagen, Impfempfehlungen sind ja nicht \" Wünsch dir was \", sondern es geht darum, Gesundheit zu erhalten, Infektionen zu verhindern und den Menschen ein sicheres Konzept an die Hand zu geben. Ich kann aber wiederum nachvollziehen, dass Politiker es gerne mal anders hätten, weil sie ein bestimmtes politisches Ziel als opportun ansehen und erreichen wollen. Aber das darf nicht'"
      ]
     },
     "metadata": {},
     "execution_count": 345
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "source": [
    "print(f'Length of original text: {len(text)}')\n",
    "print(f'Length of reconstructed text: {len(reconstructed_text)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length of original text: 2661\n",
      "Length of reconstructed text: 2681\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "source": [
    "rouge.get_scores(text, reconstructed_text)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.9545454545454546,\n",
       "   'p': 0.8786610878661087,\n",
       "   'f': 0.9150326747471297},\n",
       "  'rouge-2': {'r': 0.9271781534460338,\n",
       "   'p': 0.8642424242424243,\n",
       "   'f': 0.8946047628857197},\n",
       "  'rouge-l': {'r': 0.9545454545454546,\n",
       "   'p': 0.8786610878661087,\n",
       "   'f': 0.9150326747471297}}]"
      ]
     },
     "metadata": {},
     "execution_count": 346
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment 2\n",
    "Try mean over encodings of the splitted input and then decode the mean vector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "source": [
    "encoded_vectors = encoder(input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "mean = torch.mean(encoded_vectors, dim=0, keepdim=True)\n",
    "\n",
    "decoder_input_ids = torch.tensor([[autoencoder.config.encoder.bos_token_id]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "source": [
    "encoder(input_ids, attention_mask=attention_mask).keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state'])"
      ]
     },
     "metadata": {},
     "execution_count": 331
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "source": [
    "test_out = decoder(torch.tensor([[3,4]]), output_hidden_states=True, encoder_hidden_states=mean[:,0,:].reshape(1,1,768))\n",
    "conc = torch.cat([mean[:,0,:].reshape(1,1,768), test_out.hidden_states[-1][:,-1,:].reshape(1,1,768)], 1)\n",
    "conc.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 387
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "source": [
    "test_out.hidden_states[-1][:,-1,:].reshape(1,1,768).size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 386
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "source": [
    "i = 0\n",
    "max_i = split_size\n",
    "\n",
    "hs = mean[:,0,:].reshape(1,1,768)\n",
    "\n",
    "while i < max_i:\n",
    "    i = i+1\n",
    "    outputs = decoder(decoder_input_ids, output_hidden_states=True, encoder_hidden_states=hs)\n",
    "    hs = torch.cat([hs, outputs.hidden_states[-1][:,-1,:].reshape(1,1,768)], 1)\n",
    "    next_token_logits = outputs.logits[:,-1:]\n",
    "    next_tokens_scores = decoder._get_logits_processor(\n",
    "        repetition_penalty=decoder.config.repetition_penalty,\n",
    "        no_repeat_ngram_size=decoder.config.no_repeat_ngram_size,\n",
    "        encoder_no_repeat_ngram_size=decoder.config.encoder_no_repeat_ngram_size,\n",
    "        encoder_input_ids=None,\n",
    "        bad_words_ids=None,\n",
    "        min_length=decoder.config.min_length,\n",
    "        max_length=decoder.config.max_length,\n",
    "        eos_token_id=decoder.config.eos_token_id,\n",
    "        forced_bos_token_id=decoder.config.forced_bos_token_id,\n",
    "        forced_eos_token_id=decoder.config.forced_eos_token_id,\n",
    "        prefix_allowed_tokens_fn=None,\n",
    "        num_beams=decoder.config.num_beams,\n",
    "        num_beam_groups=decoder.config.num_beam_groups,\n",
    "        diversity_penalty=decoder.config.diversity_penalty,\n",
    "        remove_invalid_values=decoder.config.remove_invalid_values,\n",
    "    )(decoder_input_ids, next_token_logits)\n",
    "    next_decoder_input_ids = torch.argmax(next_tokens_scores, axis=-1)\n",
    "    decoder_input_ids = torch.cat([decoder_input_ids, next_decoder_input_ids], axis=-1)\n",
    "    if next_decoder_input_ids[0][0] == decoder.config.pad_token_id:\n",
    "        print(\"End of Summary!\")\n",
    "        break\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "source": [
    "summary = tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True)\n",
    "summary"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[CLS] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]'"
      ]
     },
     "metadata": {},
     "execution_count": 391
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "torch.cat([torch.tensor([[autoencoder.config.encoder.bos_token_id]]), splitted_input_ids[1]], dim=1).size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 115])"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "source": [
    "outputs = decoder(torch.tensor([[3]]), encoder_hidden_states=torch.mean(encoded_vectors[0:2,:,:], dim=0, keepdim=True))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "source": [
    "next_token_logits = outputs.logits[:,-1,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "source": [
    "torch.argmax(next_token_logits, dim=-1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([114])"
      ]
     },
     "metadata": {},
     "execution_count": 233
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "next_tokens_scores = decoder._get_logits_processor(\n",
    "    repetition_penalty=decoder.config.repetition_penalty,\n",
    "    no_repeat_ngram_size=decoder.config.no_repeat_ngram_size,\n",
    "    encoder_no_repeat_ngram_size=decoder.config.encoder_no_repeat_ngram_size,\n",
    "    encoder_input_ids=None,\n",
    "    bad_words_ids=None,\n",
    "    min_length=decoder.config.min_length,\n",
    "    max_length=decoder.config.max_length,\n",
    "    eos_token_id=decoder.config.eos_token_id,\n",
    "    forced_bos_token_id=decoder.config.forced_bos_token_id,\n",
    "    forced_eos_token_id=decoder.config.forced_eos_token_id,\n",
    "    prefix_allowed_tokens_fn=None,\n",
    "    num_beams=decoder.config.num_beams,\n",
    "    num_beam_groups=decoder.config.num_beam_groups,\n",
    "    diversity_penalty=decoder.config.diversity_penalty,\n",
    "    remove_invalid_values=decoder.config.remove_invalid_values,\n",
    ")(decoder_input_ids, next_token_logits)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "torch.argmax(next_tokens_scores, dim=-1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([6743])"
      ]
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "source": [
    "decoder_input_ids"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[3]])"
      ]
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "source": [
    "next_decoder_input_ids"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([6743])"
      ]
     },
     "metadata": {},
     "execution_count": 212
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "source": [
    "splitted_input_ids[0].size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 156])"
      ]
     },
     "metadata": {},
     "execution_count": 264
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment 3\n",
    "Split text before tokenization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "source": [
    "chunk_size = int(math.ceil(len(text) / 8))\n",
    "splitted_texts = [text[0+i:chunk_size+i] for i in range(0, len(text), chunk_size)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "source": [
    "tokenized_content = tokenizer(splitted_texts, add_special_tokens=True, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "tokenized_content.input_ids.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8, 166])"
      ]
     },
     "metadata": {},
     "execution_count": 280
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "source": [
    "generated = autoencoder.generate(tokenized_content.input_ids, attention_mask=tokenized_content.attention_mask, max_length=166, decoder_start_token_id=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "reconstructed_text = ' '.join(tokenizer.batch_decode(generated, skip_special_tokens=True))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "source": [
    "encoded_vectors = encoder(tokenized_content.input_ids, attention_mask=tokenized_content.attention_mask).last_hidden_state\n",
    "mean = torch.mean(encoded_vectors, dim=0, keepdim=True)\n",
    "\n",
    "#decoder_input_ids = torch.tensor([[autoencoder.config.encoder.bos_token_id]])\n",
    "# this is not working... try starting with the first words\n",
    "decoder_input_ids = tokenized_content.input_ids[0][:10].reshape(1,10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "source": [
    "mean.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 166, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 292
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "source": [
    "i = 0\n",
    "max_i = 166\n",
    "\n",
    "while i < max_i:\n",
    "    i = i+1\n",
    "    outputs = decoder(decoder_input_ids, encoder_hidden_states=mean)\n",
    "    next_token_logits = outputs.logits[:,-1:]\n",
    "    next_tokens_scores = decoder._get_logits_processor(\n",
    "        repetition_penalty=decoder.config.repetition_penalty,\n",
    "        no_repeat_ngram_size=decoder.config.no_repeat_ngram_size,\n",
    "        encoder_no_repeat_ngram_size=decoder.config.encoder_no_repeat_ngram_size,\n",
    "        encoder_input_ids=None,\n",
    "        bad_words_ids=None,\n",
    "        min_length=decoder.config.min_length,\n",
    "        max_length=decoder.config.max_length,\n",
    "        eos_token_id=decoder.config.eos_token_id,\n",
    "        forced_bos_token_id=decoder.config.forced_bos_token_id,\n",
    "        forced_eos_token_id=decoder.config.forced_eos_token_id,\n",
    "        prefix_allowed_tokens_fn=None,\n",
    "        num_beams=decoder.config.num_beams,\n",
    "        num_beam_groups=decoder.config.num_beam_groups,\n",
    "        diversity_penalty=decoder.config.diversity_penalty,\n",
    "        remove_invalid_values=decoder.config.remove_invalid_values,\n",
    "    )(decoder_input_ids, next_token_logits)\n",
    "    next_decoder_input_ids = torch.argmax(next_tokens_scores, axis=-1)\n",
    "    decoder_input_ids = torch.cat([decoder_input_ids, next_decoder_input_ids], axis=-1)\n",
    "    if next_decoder_input_ids[0][0] == decoder.config.pad_token_id:\n",
    "        print(\"End of Summary!\")\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "source": [
    "summary = tokenizer.decode(decoder_input_ids[0], skip_special_tokens=False)\n",
    "summary"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[CLS] STIKO - Mitglied Zepp [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk )sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk )sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk )sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sksk [SEP]sk )sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk )sk [SEP]sk [SEP]sk )sk [SEP]sk [SEP]sk [SEP]sk [SEP]sk [SEP]'"
      ]
     },
     "metadata": {},
     "execution_count": 318
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "source": [
    "decoder_input_ids"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[    3,    24, 26943, 26946]])"
      ]
     },
     "metadata": {},
     "execution_count": 301
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "source": [
    "torch.argmax(decoder(tokenized_content.input_ids[0][:10].reshape(1,10), encoder_hidden_states=mean).logits[:,-1:], axis=-1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[4]])"
      ]
     },
     "metadata": {},
     "execution_count": 315
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "source": [
    "decoder_input_ids.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "metadata": {},
     "execution_count": 299
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "source": [
    "tokenizer.decode(tokenized_content.input_ids[0][:10])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[CLS] STIKO - Mitglied Zepp'"
      ]
     },
     "metadata": {},
     "execution_count": 312
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('master-thesis-local': conda)"
  },
  "interpreter": {
   "hash": "1706a1f9fafbe48da51d8a59bfe5d85cc51c707f0120bcd96cec0e9735d555a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}